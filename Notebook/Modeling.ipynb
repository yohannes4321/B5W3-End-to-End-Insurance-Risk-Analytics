{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77b5118",
   "metadata": {},
   "source": [
    "Claim Severity Prediction (Risk Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4141ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\4287355953.py:2: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv('../Data/MachineLearningRating_v3.txt',sep='|')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('../Data/MachineLearningRating_v3.txt',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a800894b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2004, 2006, 2009, 2011, 2007, 2014, 2010, 2013, 2008, 2015, 2012,\n",
       "       2005, 1998, 1995, 2000, 2003, 1999, 2001, 1997, 1994, 2002, 1996,\n",
       "       1992, 1987, 1988])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RegistrationYear'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b5dae",
   "metadata": {},
   "source": [
    "feature engennering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fc7e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_df=df[df['TotalClaims'] >0].copy()\n",
    "df['Vehicle_Age']=2023-df['RegistrationYear']\n",
    " \n",
    "\n",
    "#feature exteraction \n",
    "x=claim_df[[ 'RegistrationYear', 'Province', 'NewVehicle', 'Vehicle_Age','Gender']]\n",
    "\n",
    "y=claim_df['TotalClaims']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11ba3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RegistrationYear', 'Vehicle_Age']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols=x.select_dtypes(include=['object','category']).columns.to_list()\n",
    "numerical_cols=x.select_dtypes(include=['float64','int64']).columns.to_list()\n",
    "print(numerical_cols)\n",
    "numerical_df=x[['RegistrationYear', 'Vehicle_Age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695048c8",
   "metadata": {},
   "source": [
    "handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86e96af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\545793836.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  x[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\545793836.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\545793836.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  x[col].fillna(most_common, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\545793836.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[col].fillna(most_common, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\545793836.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  x[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\545793836.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\545793836.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  x[col].fillna(most_common, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\545793836.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[col].fillna(most_common, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in x.columns:\n",
    "    if x[col].dtype=='object':   \n",
    "        most_common= x[col].mode()[0]   \n",
    "        x[col].fillna(most_common, inplace=True)\n",
    "    else:  # Numerical columns\n",
    "        median_val = x[col].median()\n",
    "        x[col].fillna(median_val, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d06204",
   "metadata": {},
   "source": [
    "handle missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76eb829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Province_Eastern Cape' 'Province_Free State' 'Province_Gauteng'\n",
      " 'Province_KwaZulu-Natal' 'Province_Limpopo' 'Province_Mpumalanga'\n",
      " 'Province_North West' 'Province_Northern Cape' 'Province_Western Cape'\n",
      " 'NewVehicle_More than 6 months' 'Gender_Female' 'Gender_Male'\n",
      " 'Gender_Not specified']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder=OneHotEncoder(handle_unknown='ignore')\n",
    "encoded_cols=encoder.fit(x[categorical_cols])\n",
    "feature_names=encoded_cols.get_feature_names_out(categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83322cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_cols = encoder.fit_transform(x[categorical_cols])\n",
    "encoded_df=pd.DataFrame(encoded_cols,columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7668a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x=pd.concat([encoded_df,numerical_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_sev,x_test_sev,y_train_sev,y_test_sev=train_test_split(test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6b454",
   "metadata": {},
   "source": [
    "Claim Probablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3680b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\1365624263.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[c]=x[c].fillna(x[c].mode())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Province      object\n",
      "NewVehicle    object\n",
      "Gender        object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\1365624263.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[c]=x[c].fillna(x[c].median())\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\1365624263.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[c]=x[c].fillna(x[c].median())\n"
     ]
    }
   ],
   "source": [
    "x=df[ ['RegistrationYear', 'Province', 'NewVehicle', 'Vehicle_Age','Gender']]\n",
    "y=df['Has_Claim']\n",
    "categorical_cols=x.select_dtypes(exclude=['float64','int64'])\n",
    "numerical_cols=x.select_dtypes(include=['float64','int64'])\n",
    "for c in categorical_cols:\n",
    "    x[c]=x[c].fillna(x[c].mode())\n",
    "for c in numerical_cols:\n",
    "    x[c]=x[c].fillna(x[c].median())\n",
    "print(categorical_cols.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e3c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17792\\3753894760.py:15: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../Data/MachineLearningRating_v3.txt', sep='|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "CLAIM SEVERITY MODELS (REGRESSION)\n",
      "==================================================\n",
      "Linear Regression:\n",
      "  RMSE: 38702.90\n",
      "  R-squared: 0.0686\n",
      "--------------------------------------------------\n",
      "Decision Tree:\n",
      "  RMSE: 33400.17\n",
      "  R-squared: 0.3063\n",
      "--------------------------------------------------\n",
      "Random Forest:\n",
      "  RMSE: 36493.05\n",
      "  R-squared: 0.1719\n",
      "--------------------------------------------------\n",
      "XGBoost:\n",
      "  RMSE: 38190.34\n",
      "  R-squared: 0.0931\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "CLAIM PROBABILITY MODELS (CLASSIFICATION)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "  Accuracy: 0.9971\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1 Score: 0.0000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "  Accuracy: 0.9971\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1 Score: 0.0000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import shap\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../Data/MachineLearningRating_v3.txt', sep='|')\n",
    "\n",
    "# Feature Engineering - create copies to avoid chained assignment\n",
    "df = df.copy()\n",
    "df['Has_Claim'] = (df['TotalClaims'] > 0).astype(int)\n",
    "df['Vehicle_Age'] = 2023 - df['RegistrationYear']\n",
    "\n",
    "# 1. CLAIM SEVERITY MODEL - Only policies with claims\n",
    "claim_df = df[df['TotalClaims'] > 0].copy()\n",
    "\n",
    "# Feature selection\n",
    "features_severity = ['VehicleType', 'Vehicle_Age', 'Province', 'cubiccapacity', 'SumInsured']\n",
    "target_severity = 'TotalClaims'\n",
    "\n",
    "# Create a copy for processing\n",
    "X_sev = claim_df[features_severity].copy()\n",
    "y_sev = claim_df[target_severity].copy()\n",
    "\n",
    "# Handle missing values without chained assignment\n",
    "for col in X_sev.columns:\n",
    "    if X_sev[col].dtype == 'object':\n",
    "        fill_val = X_sev[col].mode()[0] if not X_sev[col].mode().empty else 'Missing'\n",
    "        X_sev.loc[:, col] = X_sev[col].fillna(fill_val)\n",
    "    else:\n",
    "        fill_val = X_sev[col].median()\n",
    "        X_sev.loc[:, col] = X_sev[col].fillna(fill_val)\n",
    "\n",
    "# One-Hot Encoding\n",
    "X_sev_encoded = pd.get_dummies(X_sev, columns=['VehicleType', 'Province'], drop_first=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sev, X_test_sev, y_train_sev, y_test_sev = train_test_split(\n",
    "    X_sev_encoded, y_sev, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. CLAIM PROBABILITY MODEL - All policies\n",
    "features_prob = ['Vehicle_Age', 'Gender', 'Province', 'SumInsured', 'VehicleType']\n",
    "target_prob = 'Has_Claim'\n",
    "\n",
    "# Create a copy for processing\n",
    "X_prob = df[features_prob].copy()\n",
    "y_prob = df[target_prob].copy()\n",
    "\n",
    "# Handle missing values without chained assignment\n",
    "for col in X_prob.columns:\n",
    "    if X_prob[col].dtype == 'object':\n",
    "        fill_val = X_prob[col].mode()[0] if not X_prob[col].mode().empty else 'Missing'\n",
    "        X_prob.loc[:, col] = X_prob[col].fillna(fill_val)\n",
    "    else:\n",
    "        fill_val = X_prob[col].median()\n",
    "        X_prob.loc[:, col] = X_prob[col].fillna(fill_val)\n",
    "\n",
    "# One-Hot Encoding\n",
    "X_prob_encoded = pd.get_dummies(X_prob, columns=['Gender', 'Province', 'VehicleType'], drop_first=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train_prob, X_test_prob, y_train_prob, y_test_prob = train_test_split(\n",
    "    X_prob_encoded, y_prob, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =====================================================================\n",
    "# MODEL BUILDING AND EVALUATION - REGRESSION (Claim Severity)\n",
    "# =====================================================================\n",
    "def train_evaluate_regression(models, X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'RMSE': rmse,\n",
    "            'R-squared': r2,\n",
    "            'model': model\n",
    "        }\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  RMSE: {rmse:.2f}\")\n",
    "        print(f\"  R-squared: {r2:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Regression models\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"CLAIM SEVERITY MODELS (REGRESSION)\")\n",
    "print(\"=\" * 50)\n",
    "severity_results = train_evaluate_regression(reg_models, X_train_sev, X_test_sev, y_train_sev, y_test_sev)\n",
    "\n",
    "# =====================================================================\n",
    "# MODEL BUILDING AND EVALUATION - CLASSIFICATION (Claim Probability)\n",
    "# =====================================================================\n",
    "def train_evaluate_classification(models, X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1': f1,\n",
    "            'model': model\n",
    "        }\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Accuracy: {acc:.4f}\")\n",
    "        print(f\"  Precision: {prec:.4f}\")\n",
    "        print(f\"  Recall: {rec:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Classification models\n",
    "clf_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CLAIM PROBABILITY MODELS (CLASSIFICATION)\")\n",
    "print(\"=\" * 50)\n",
    "prob_results = train_evaluate_classification(clf_models, X_train_prob, X_test_prob, y_train_prob, y_test_prob)\n",
    "\n",
    "# =====================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. For Severity Model (Random Forest)\n",
    "best_sev_model = severity_results['Random Forest']['model']\n",
    "importances = best_sev_model.feature_importances_\n",
    "feature_names = X_train_sev.columns\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Features for Claim Severity (Random Forest):\")\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "plt.title('Top 10 Features - Claim Severity Prediction')\n",
    "plt.tight_layout()\n",
    "plt.savefig('severity_feature_importance.png')\n",
    "plt.show()\n",
    "\n",
    "# 2. For Probability Model (XGBoost)\n",
    "best_prob_model = prob_results['XGBoost']['model']\n",
    "importances_prob = best_prob_model.feature_importances_\n",
    "feature_names_prob = X_train_prob.columns\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "importance_prob_df = pd.DataFrame({\n",
    "    'Feature': feature_names_prob,\n",
    "    'Importance': importances_prob\n",
    "}).sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Features for Claim Probability (XGBoost):\")\n",
    "print(importance_prob_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_prob_df)\n",
    "plt.title('Top 10 Features - Claim Probability Prediction')\n",
    "plt.tight_layout()\n",
    "plt.savefig('probability_feature_importance.png')\n",
    "plt.show()\n",
    "\n",
    "# =====================================================================\n",
    "# SHAP ANALYSIS\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SHAP ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. For Severity Model\n",
    "print(\"\\nSHAP Analysis for Claim Severity (Random Forest):\")\n",
    "explainer_sev = shap.TreeExplainer(best_sev_model)\n",
    "shap_values_sev = explainer_sev.shap_values(X_test_sev)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values_sev, X_test_sev, feature_names=feature_names.tolist(), show=False)\n",
    "plt.title('SHAP Summary - Claim Severity')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_severity.png')\n",
    "plt.show()\n",
    "\n",
    "# 2. For Probability Model\n",
    "print(\"\\nSHAP Analysis for Claim Probability (XGBoost):\")\n",
    "explainer_prob = shap.TreeExplainer(best_prob_model)\n",
    "shap_values_prob = explainer_prob.shap_values(X_test_prob)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values_prob, X_test_prob, feature_names=feature_names_prob.tolist(), show=False)\n",
    "plt.title('SHAP Summary - Claim Probability')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_probability.png')\n",
    "plt.show()\n",
    "\n",
    "# =====================================================================\n",
    "# MODEL COMPARISON REPORT\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MODEL COMPARISON REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Regression model comparison\n",
    "print(\"\\nRegression Models Performance (Claim Severity):\")\n",
    "reg_comparison = pd.DataFrame({\n",
    "    model: {metric: values[metric] for metric in ['RMSE', 'R-squared']}\n",
    "    for model, values in severity_results.items()\n",
    "}).T\n",
    "print(reg_comparison)\n",
    "\n",
    "# Classification model comparison\n",
    "print(\"\\nClassification Models Performance (Claim Probability):\")\n",
    "clf_comparison = pd.DataFrame({\n",
    "    model: {metric: values[metric] for metric in ['Accuracy', 'Precision', 'Recall', 'F1']}\n",
    "    for model, values in prob_results.items()\n",
    "}).T\n",
    "print(clf_comparison)\n",
    "\n",
    "# Save results to CSV\n",
    "reg_comparison.to_csv('regression_model_comparison.csv')\n",
    "clf_comparison.to_csv('classification_model_comparison.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ef86968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.48.0-cp313-cp313-win_amd64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from shap) (2.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from shap) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from shap) (1.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from shap) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from shap) (25.0)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numba>=0.54 (from shap)\n",
      "  Downloading numba-0.61.2-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from shap) (4.14.0)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.54->shap)\n",
      "  Downloading llvmlite-0.44.0-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting numpy (from shap)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->shap) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Downloading shap-0.48.0-cp313-cp313-win_amd64.whl (545 kB)\n",
      "   ---------------------------------------- 0.0/545.1 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/545.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 545.1/545.1 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading numba-0.61.2-cp313-cp313-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.0/2.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.3/2.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.8/2.8 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.8 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.4/2.8 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.8 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.44.0-cp313-cp313-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/30.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/30.3 MB 1.7 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.8/30.3 MB 1.7 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 1.3/30.3 MB 1.5 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 1.6/30.3 MB 1.5 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 1.8/30.3 MB 1.5 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 2.1/30.3 MB 1.5 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 2.4/30.3 MB 1.5 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 2.9/30.3 MB 1.5 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 3.1/30.3 MB 1.5 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 3.4/30.3 MB 1.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 3.9/30.3 MB 1.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 4.2/30.3 MB 1.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 4.5/30.3 MB 1.5 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 5.0/30.3 MB 1.6 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 5.5/30.3 MB 1.6 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 6.0/30.3 MB 1.7 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 6.3/30.3 MB 1.7 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 6.8/30.3 MB 1.7 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 7.3/30.3 MB 1.7 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 7.9/30.3 MB 1.8 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 8.4/30.3 MB 1.8 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 8.9/30.3 MB 1.8 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 9.4/30.3 MB 1.9 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 10.0/30.3 MB 1.9 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 10.7/30.3 MB 1.9 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 11.5/30.3 MB 2.0 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 12.1/30.3 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 12.8/30.3 MB 2.1 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 13.4/30.3 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 14.2/30.3 MB 2.2 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 14.9/30.3 MB 2.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 15.7/30.3 MB 2.3 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 15.7/30.3 MB 2.3 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 16.8/30.3 MB 2.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 17.6/30.3 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 18.4/30.3 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 18.9/30.3 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 19.7/30.3 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 20.2/30.3 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 20.4/30.3 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 21.5/30.3 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 21.8/30.3 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 22.3/30.3 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 22.5/30.3 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 23.1/30.3 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 23.6/30.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 24.1/30.3 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 24.9/30.3 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 25.4/30.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 26.0/30.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 26.5/30.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 27.3/30.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 27.8/30.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 28.3/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.8/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 29.1/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.6/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.1/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.1/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 2.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.8/12.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 2.3 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 2.2 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.4/12.6 MB 2.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/12.6 MB 2.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.1/12.6 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 2.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 4.2/12.6 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 4.5/12.6 MB 2.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 5.0/12.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.0/12.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.3/12.6 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.8/12.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.6/12.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.1/12.6 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 8.4/12.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.0/12.6 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.5/12.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: slicer, numpy, llvmlite, cloudpickle, numba, shap\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.3.0\n",
      "\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "    Uninstalling numpy-2.3.0:\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "      Successfully uninstalled numpy-2.3.0\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------ --------------------------------- 1/6 [numpy]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   --------------------------------- ------ 5/6 [shap]\n",
      "   ---------------------------------------- 6/6 [shap]\n",
      "\n",
      "Successfully installed cloudpickle-3.1.1 llvmlite-0.44.0 numba-0.61.2 numpy-2.2.6 shap-0.48.0 slicer-0.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de62c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
